{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we model subgroups of families, workplaces etc., which will determine the probability of exposure. \n",
    "We will base this on the earlier described SIR model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I' 'S' 'S' ... 'S' 'S' 'S']\n",
      " ['I' 'S' 'S' ... 'S' 'S' 'S']]\n"
     ]
    }
   ],
   "source": [
    "# Define number of people (you may change here)\n",
    "n = 1000\n",
    "\n",
    "# Define number of families (you may change here)\n",
    "n_families = 10\n",
    "family_types = np.arange(1,n_families+1)\n",
    "\n",
    "# Define work types (you may change here)\n",
    "work_types = np.array([\"BYG\", \"MMC\", \"KBS\", \"WIND\"])\n",
    "work_probs = np.array([0.1, 0.2, 0.4, 0.3])\n",
    "n_work_types = len(work_types)\n",
    "\n",
    "# Define vector of states\n",
    "states = np.repeat(\"S\",n)\n",
    "states[0] = \"I\"\n",
    "states_matrix = np.copy([states])\n",
    "\n",
    "\n",
    "states_matrix = np.vstack((states_matrix, states ))\n",
    "print(states_matrix)\n",
    "\n",
    "# Probabilities of entering \n",
    "prob_S_I = 0.9\n",
    "prob_I_R = 0.3\n",
    "\n",
    "n_S = np.array([len(np.where(states == \"S\")[0])])\n",
    "n_I = np.array([len(np.where(states == \"I\")[0])])\n",
    "n_R = np.array([len(np.where(states == \"R\")[0])])\n",
    "\n",
    "\n",
    "# Generate workplaces\n",
    "workplaces_sorted = np.sort(np.random.choice(work_types,n, p = work_probs))\n",
    "counts = np.unique(workplaces_sorted, return_counts = True)[1]\n",
    "workplaces_counts_sorted = np.repeat(counts, counts)\n",
    "random_positions = np.random.choice(np.arange(0,n), size = n, replace=False)\n",
    "\n",
    "# Update workplaces based on positions\n",
    "workplaces = workplaces_sorted[random_positions]\n",
    "workplaces_counts = workplaces_counts_sorted[random_positions]\n",
    "\n",
    "# Update families based on positions\n",
    "families = np.sort(np.random.choice(family_types, n))\n",
    "counts = np.unique(workplaces_sorted, return_counts = True)[1]\n",
    "families_counts = np.repeat(counts, counts)\n",
    "\n",
    "while (\"I\" in states):\n",
    "\n",
    "    # Get positions of S, I, R\n",
    "    S_index = np.where(states == \"S\")[0]\n",
    "    I_index = np.where(states == \"I\")[0]\n",
    "    R_index = np.where(states == \"R\")[0]\n",
    "\n",
    "    # Count infected at each worktype\n",
    "    work_I = np.zeros(n)\n",
    "    for work in work_types:\n",
    "        work_index = np.where(workplaces == work)[0]\n",
    "        work_I[work_index] += len(np.where((workplaces == work) & (states == \"I\"))[0])\n",
    "        \n",
    "    # Count infected at each family  \n",
    "    family_I = np.zeros(n)\n",
    "    for family in family_types:\n",
    "        family_index = np.where(families == family)[0]\n",
    "        family_I[family_index] += len(np.where((families == family) & (states == \"I\"))[0])\n",
    "        \n",
    "    # Calculate probability\n",
    "    prob_vector = prob_S_I * ((work_I + family_I) / (workplaces_counts + families_counts))\n",
    "\n",
    "    \n",
    "    for pos in S_index:\n",
    "        states[pos] = np.random.choice(np.array([\"S\",\"I\"]),p = np.array([1-prob_vector[pos], prob_vector[pos]]))\n",
    "        \n",
    "        \n",
    "\n",
    "    # Update infected\n",
    "    states[I_index] = np.random.choice(np.array([\"I\", \"R\"]),p = np.array([1-prob_I_R, prob_I_R]), size = len(I_index))\n",
    "    \n",
    "    \n",
    "    # Update states_matrix\n",
    "    states_matrix = np.vstack((states_matrix, states ))\n",
    "    \n",
    "    n_S = np.concatenate([n_S, np.array([len(np.where(states == \"S\")[0])])])\n",
    "    n_I = np.concatenate([n_I, np.array([len(np.where(states == \"I\")[0])])])\n",
    "    n_R = np.concatenate([n_R, np.array([len(np.where(states == \"R\")[0])])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "for fam_number in family_types[0:6]:\n",
    "    n_fam = np.array([])\n",
    "    for row in states_matrix:\n",
    "        f = len(np.where((row == \"I\")& (families == fam_number))[0])\n",
    "        n_fam = np.concatenate([n_fam, np.array([f])])\n",
    "        \n",
    "    n_frac_fam = n_fam/np.sum(families == fam_number)\n",
    "    \n",
    "    plt.plot(n_frac_fam, label = str(fam_number))\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Fraction of infected people in family\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for work_string in work_types:\n",
    "    n_work = np.array([])\n",
    "    for row in states_matrix:\n",
    "        w = len(np.where((row == \"I\")& (workplaces == work_string))[0])\n",
    "        n_work = np.concatenate([n_work, np.array([w])])\n",
    "    \n",
    "    n_frac_work = n_work/np.sum(workplaces == work_string)\n",
    "        \n",
    "    plt.plot(n_frac_work, label = work_string)\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Fraction of infected people in work group\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
